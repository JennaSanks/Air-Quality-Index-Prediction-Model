{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio pandas numpy scikit-learn openpyxl"
      ],
      "metadata": {
        "id": "KiiH7datWGXP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyvG_q4PrZPn",
        "outputId": "3b687d60-9eda-47c3-ed22-06c7ae13548a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, traceback\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "XkACz_VCY4hA"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_model = None\n",
        "_scaler = None\n",
        "_features = []"
      ],
      "metadata": {
        "id": "4zZ2oJPMY9Cp"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _load_file(file_obj):\n",
        "    # file_obj in Colab has .name pointing to the uploaded temp file path\n",
        "    if file_obj is None:\n",
        "        raise ValueError(\"No file provided\")\n",
        "    path = getattr(file_obj, \"name\", None)\n",
        "    if not path or not os.path.exists(path):\n",
        "        raise ValueError(\"Uploaded file path not found.\")\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xls\", \".xlsx\"]:\n",
        "        return pd.read_excel(path)\n",
        "    else:\n",
        "        # try csv, fallback to semicolon\n",
        "        try:\n",
        "            return pd.read_csv(path)\n",
        "        except Exception:\n",
        "            return pd.read_csv(path, sep=';')"
      ],
      "metadata": {
        "id": "gJpEKl61ZCNN"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(file_obj):\n",
        "    global _model, _scaler, _features\n",
        "    try:\n",
        "        df = _load_file(file_obj)\n",
        "        if \"AQI\" not in df.columns:\n",
        "            return \"‚ùå 'AQI' column missing in the dataset. Please include it.\"\n",
        "        # drop missing AQI and fill numeric missing\n",
        "        df = df.dropna(subset=[\"AQI\"]).fillna(df.mean(numeric_only=True))\n",
        "        df = df[df[\"AQI\"] > 0]  # remove invalid AQI\n",
        "\n",
        "        # detect pollutant columns\n",
        "        keys = [\"PM\", \"NO\", \"CO\", \"SO\", \"O3\", \"NH3\", \"BENZ\", \"TOLU\", \"XYL\"]\n",
        "        features = [c for c in df.columns if any(k in c.upper() for k in keys)]\n",
        "        if \"City\" in features:\n",
        "           features.remove(\"City\")\n",
        "        if not features:\n",
        "            # fallback to numeric columns except AQI\n",
        "            numeric = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "            features = [c for c in numeric if c != \"AQI\"]\n",
        "        if not features:\n",
        "            return \"‚ùå No pollutant/numeric features found. Ensure dataset has pollutant columns.\"\n",
        "        # optional: encode City\n",
        "        if \"Date\" in df.columns:\n",
        "            df[\"Month\"] = pd.to_datetime(df[\"Date\"]).dt.month\n",
        "            df[\"Day\"] = pd.to_datetime(df[\"Date\"]).dt.day\n",
        "        if \"City\" in df.columns and df[\"City\"].dtype == object:\n",
        "            try:\n",
        "                le = LabelEncoder()\n",
        "                df[\"City\"] = le.fit_transform(df[\"City\"].astype(str))\n",
        "                pass\n",
        "            except Exception:\n",
        "                pass\n",
        "        X = df[features]\n",
        "        # Clip outliers to reduce noise\n",
        "        for col in features:\n",
        "            df[col] = np.clip(df[col], df[col].quantile(0.01), df[col].quantile(0.99))\n",
        "\n",
        "        y = df[\"AQI\"]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        _scaler = StandardScaler().fit(X_train)\n",
        "        X_train_s = _scaler.transform(X_train)\n",
        "        X_test_s = _scaler.transform(X_test)\n",
        "\n",
        "        from sklearn.ensemble import RandomForestRegressor\n",
        "        from xgboost import XGBRegressor\n",
        "        # Train multiple models\n",
        "        lin_model = LinearRegression()\n",
        "        rf_model = RandomForestRegressor(\n",
        "            n_estimators=300,\n",
        "            max_depth=15,\n",
        "            min_samples_split=4,\n",
        "            min_samples_leaf=2,\n",
        "            random_state=42\n",
        "        )\n",
        "        xgb_model = XGBRegressor(\n",
        "            n_estimators=500,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=10,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Fit all models\n",
        "        lin_model.fit(X_train_s, y_train)\n",
        "        rf_model.fit(X_train_s, y_train)\n",
        "        xgb_model.fit(X_train_s, y_train)\n",
        "\n",
        "        # Combine their predictions\n",
        "        y_pred_lin = lin_model.predict(X_test_s)\n",
        "        y_pred_rf = rf_model.predict(X_test_s)\n",
        "        y_pred_xgb = xgb_model.predict(X_test_s)\n",
        "\n",
        "        # Average predictions (ensemble)\n",
        "        y_pred = (0.2 * y_pred_lin + 0.3 * y_pred_rf + 0.5 * y_pred_xgb)\n",
        "\n",
        "        # Evaluate\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        accuracy = r2 * 100\n",
        "\n",
        "        # Save the ensemble (you can pick one model to store if needed)\n",
        "        _model = rf_model  # optional, to use later for manual prediction\n",
        "        _features = features\n",
        "        result = (f\"‚úÖ Model trained!\\nDetected features: {', '.join(features)}\\n\\n\"\n",
        "            f\"MAE: {mae:.2f} | RMSE: {rmse:.2f} | R¬≤: {r2:.3f} | Accuracy ‚âà {accuracy:.1f}%\")\n",
        "        print(result)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return \"‚ùå Training failed: \" + str(e) + \"\\n\\n\" + traceback.format_exc()"
      ],
      "metadata": {
        "id": "DigiQorvZHYW"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_manual(text):\n",
        "    global _model, _scaler, _features\n",
        "    if _model is None:\n",
        "        return \"‚ö†Ô∏è Train the model first.\"\n",
        "    if not text:\n",
        "        return \"‚ö†Ô∏è Paste comma-separated pollutant values matching detected features.\"\n",
        "    try:\n",
        "        vals = [float(x.strip()) for x in text.split(\",\")]\n",
        "        if len(vals) != len(_features):\n",
        "            return f\"‚ö†Ô∏è Expected {len(_features)} values (features: {', '.join(_features)}). You provided {len(vals)}.\"\n",
        "        arr = np.array(vals).reshape(1, -1)\n",
        "        arr_s = _scaler.transform(arr)\n",
        "        pred = _model.predict(arr_s)[0]\n",
        "        return f\"üå§Ô∏è Predicted AQI: {pred:.2f}\"\n",
        "    except Exception as e:\n",
        "        return \"‚ùå Prediction error: \" + str(e)"
      ],
      "metadata": {
        "id": "nzkusUBGZKw1"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## AQI Predictor ‚Äî Minimal (Upload dataset, Train, Predict)\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            file_in = gr.File(label=\"Upload CSV or Excel (must include 'AQI')\")\n",
        "            train_btn = gr.Button(\"Train Model\")\n",
        "            train_out = gr.Textbox(label=\"Training Output\", lines=6)\n",
        "        with gr.Column():\n",
        "            manual_in = gr.Textbox(label=\"Paste comma-separated pollutant values (order shown after training)\", placeholder=\"e.g. 50,80,10,30,...\")\n",
        "            pred_btn = gr.Button(\"Predict AQI\")\n",
        "            pred_out = gr.Textbox(label=\"Prediction Output\", lines=2)\n",
        "    train_btn.click(train, inputs=file_in, outputs=train_out)\n",
        "    pred_btn.click(predict_manual, inputs=manual_in, outputs=pred_out)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "QPQiWlkVUI65",
        "outputId": "cb488811-3a06-42a3-e199-93da294dc899"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://8755e9b4df00f7f453.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8755e9b4df00f7f453.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ]
}